\documentclass[10pt]{beamer}
\usepackage{bbm}
\usepackage{fontspec}

\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{animate}
\renewcommand\appendixname{Appendix}
\usepackage{xcolor}
\usepackage{tikz}
\colorlet{rred}{red!80!black}
\colorlet{ggreen}{green!80!black}




\usetheme[progressbar=foot]{metropolis}
\usepackage{appendixnumberbeamer}
\setbeamercovered{dynamic}

\usepackage{booktabs}
\usepackage[scale=2]{ccicons}

\usepackage{pgfplots}
\usepgfplotslibrary{dateplot}
\setbeamertemplate{caption}{\raggedright\insertcaption\par}
\setlength{\abovecaptionskip}{-10pt plus 0pt minus 0pt}

\usepackage{xspace}
\newcommand{\themename}{\textbf{\textsc{metropolis}}\xspace}
\theoremstyle{definition}
\newtheorem{defn}{Definition}
\newtheorem{obs}{Observation}

% math symbols
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\1}{\mathbbm{1}}
\newcommand{\XX}{\mathcal{X}}
\newcommand{\TT}{\mathcal{T}}
\newcommand{\YY}{\mathcal{Y}}
\newcommand{\UU}{\mathcal{U}}
\newcommand{\VV}{\mathcal{V}}
\newcommand{\WW}{\mathcal{W}}
\newcommand{\LL}{\mathcal{L}}

\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
\title{Stochastic Neighborhood Embedding}
\subtitle{Weekly AI pills}
\date{2020-11-13}
\author{Fabio Brau.}
\institute{SSSA, Emerging Digital Technologies, Pisa.}
% \titlegraphic{\hfill\includegraphics[height=1.5cm]{logo.pdf}}

\usebackgroundtemplate{%
    \begin{picture}(300,271)
      \hspace{11.2cm}
       \includegraphics[scale=0.1]{pic/logoretis_noname.png}
   \end{picture}}

\begin{document}
{\usebackgroundtemplate{%
    \begin{picture}(300,265)
      \hspace{0.9cm}
       \includegraphics[scale=0.5]{pic/tecip_logo.png}
       \hspace{0.5cm}
       \includegraphics[scale=0.21]{pic/logoretis_320.png}
   \end{picture}}%
\maketitle
}
\begin{frame}{Summary}
  \begin{enumerate}
    \item Entropy and Kullbackâ€“Leibler divergence
    \item From SNE to t-SNE
    \item Application for Visualization
    \item Issues
  \end{enumerate}
\end{frame}
\begin{frame}{t-SNE}{}

  {\bf Main Papers}\\
    Stochastic Neighbor Embedding - Hinton \& Roweis - 2002\\
    Visualizing Data using t-SNE - Maaten \& Hinton - 2008\\
    \vfill
  {\bf Aim : Visualize Data}
  \begin{equation}
    \begin{rcases}
      x\in\R^n \\
      \mbox{Images} \\
      \mbox{Text}
    \end{rcases}\overset{\Phi}{\longrightarrow} \R^2
  \end{equation}

  
\end{frame}
\section{Entropy}
\begin{frame}{Shannon Entropy}{}
  {\it ``The Entropy measures the complexity of the information''}
  \begin{equation}
    H(p_1,\cdots,p_n) = -\frac{1}{n}\sum_i p_i\log_2(p_i)
    \label{entropy}
  \end{equation}
\end{frame}
\end{document}

